{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "import sys\n",
    "import pepper_kinematics as pk\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "p = n.ALProxy(\"ALRobotPosture\", nao_ip, port)\n",
    "mr = n.ALProxy(\"ALMotionRecorder\", nao_ip, port)\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "Ph = n.ALProxy(\"ALPhotoCapture\", nao_ip, port)\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Posture stand Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to initial pose\n",
    "p.goToPosture(\"StandInit\",0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관절 lock 해제\n",
    "m.setStiffnesses(\"LArm\",0.1)\n",
    "stiffnesses = m.getStiffnesses(\"LArm\")\n",
    "print stiffnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.post.startPeriodicRecording(pk.left_arm_tags, 0, True, 0.5, [], [])\n",
    "time.sleep(10)\n",
    "move = mr.stopAndGetRecording()\n",
    "# print move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = []\n",
    "for y in range (0,len(move[0][1])):\n",
    "    replay.append([move[x][1][y] for x in range(0,5)]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(replay)):\n",
    "    m.setAngles(pk.left_arm_tags, replay[x], 0.08)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관절 lock 해제\n",
    "m.setStiffnesses(\"LArm\",1.0)\n",
    "stiffnesses = m.getStiffnesses(\"LArm\")\n",
    "print stiffnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "\n",
    "\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "memory = n.ALProxy(\"ALMemory\", nao_ip, port)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if memory.getData(\"FrontTactilTouched\") :\n",
    "        print(time.ctime())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.521554, 0.467864, 0.648874, 0.547631, 0.547631, 0.00872665])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.20878, 1.19804, 1.22718, 1.24252, 1.24252, 1.25633])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.543937, 0.532513, 0.532513, 0.532513, 0.532513, 0.529877])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.33303, 1.05384, 0.420311, 0.541495, 0.541495, 1.31002])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([-0.693359, -1.20724, -0.81301, -0.211689, -0.211689, -0.0981748])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.302156, 0.628898, 0.361982, 0.277612, 0.277612, -0.242414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "time.sleep(3)\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    cv2.imwrite('images/save_encoding_%d.jpg' %(y), color_image)\n",
    "\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "time.sleep(3)\n",
    "frames = pipeline.wait_for_frames()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "color_frame = frames.get_color_frame()\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "cv2.imwrite('images/save_encodiwng_1.jpg', color_image)\n",
    "pipeline.stop()\n",
    "# Stack both images horizontally\n",
    "# images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "\n",
    "# Show images\n",
    "#cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "#cv2.imshow('RealSense', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- encoding: UTF-8 -*-\n",
    "\n",
    "\"\"\"Example: Get an image. Display it and save it using PIL.\"\"\"\n",
    "\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "# Get the service ALVideoDevice.\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 1 ,resolution, colorSpace, 5)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get a camera image.\n",
    "# image[6] contains the image data passed as an array of ASCII chars.\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Time the image transfer.\n",
    "print \"acquisition delay \", t1 - t0\n",
    "\n",
    "V.unsubscribe(videoClient)\n",
    "\n",
    "\n",
    "# Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "# package.\n",
    "\n",
    "# Get the image size and pixel array.\n",
    "imageWidth = naoImage[0]\n",
    "imageHeight = naoImage[1]\n",
    "naoImage[7] = 1\n",
    "array = naoImage[6]\n",
    "\n",
    "\n",
    "image_byte = str(bytearray(array))\n",
    "\n",
    "# Create a PIL Image from our pixel array.\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "\n",
    "# Save the image.\n",
    "im.save(\"camImage.png\", \"PNG\")\n",
    "\n",
    "im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replay motion capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.ab\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.521554, 0.467864, 0.648874, 0.547631, 0.547631, 0.00872665])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.20878, 1.19804, 1.22718, 1.24252, 1.24252, 1.25633])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.543937, 0.532513, 0.532513, 0.532513, 0.532513, 0.529877])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.33303, 1.05384, 0.420311, 0.541495, 0.541495, 1.31002])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([-0.693359, -1.20724, -0.81301, -0.211689, -0.211689, -0.0981748])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.302156, 0.628898, 0.361982, 0.277612, 0.277612, -0.242414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 1 ,resolution, colorSpace, 5)\n",
    "\n",
    "imageWidth = 640\n",
    "imageHeight = 480\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);color_frame\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n",
    "    naoImage = V.getImageRemote(videoClient)\n",
    "    array = naoImage[6]\n",
    "    image_byte = str(bytearray(array))\n",
    "    im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "    im.save(\"images/motion_catpure%i.png\" %y, \"PNG\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\tALVideoRecorder::startRecording\n\tboost::filesystem::create_directories: Permission denied: \"/home/beom\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f855968b15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mVR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCameraID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mVR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRecording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/beom/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"video\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/beom/naoqi/pynaoqi-python2.7-2.5.5.5-linux64/lib/python2.7/site-packages/naoqi.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__method__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__method__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMethodMissing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/beom/naoqi/pynaoqi-python2.7-2.5.5.5-linux64/lib/python2.7/site-packages/naoqi.pyc\u001b[0m in \u001b[0;36mmethod_missing\u001b[0;34m(self, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonCall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m                 \u001b[0;31m#print e.args[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \tALVideoRecorder::startRecording\n\tboost::filesystem::create_directories: Permission denied: \"/home/beom\""
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "import sys\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "# Get the service ALVideoRecorder.\n",
    "VR = n.ALProxy(\"ALVideoRecorder\", nao_ip, port)\n",
    "\n",
    "# This records a 320*240 MJPG video at 10 fps.\n",
    "# Note MJPG can't be recorded with a framerate lower than 3 fps.\n",
    "VR.setResolution(2)\n",
    "VR.setFrameRate(10)\n",
    "VR.setVideoFormat(\"MJPG\")\n",
    "VR.setCameraID(1)\n",
    "\n",
    "VR.startRecording(\"/home/beom/\", \"video\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Video file is saved on the robot in the\n",
    "# /home/nao/recordings/cameras/ folder.\n",
    "videoInfo = VR.stopRecording()\n",
    "\n",
    "print \"Video was saved on the robot: \", videoInfo[1]\n",
    "print \"Num frames: \", videoInfo[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoInfo = VR.stopRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
