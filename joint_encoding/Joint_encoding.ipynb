{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "import sys\n",
    "import pepper_kinematics as pk\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "p = n.ALProxy(\"ALRobotPosture\", nao_ip, port)\n",
    "mr = n.ALProxy(\"ALMotionRecorder\", nao_ip, port)\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "Ph = n.ALProxy(\"ALPhotoCapture\", nao_ip, port)\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Posture stand Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move to initial pose\n",
    "p.goToPosture(\"StandInit\",0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관절 lock 해제\n",
    "m.setStiffnesses(\"LArm\",0.1)\n",
    "stiffnesses = m.getStiffnesses(\"LArm\")\n",
    "print stiffnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.post.startPeriodicRecording(pk.left_arm_tags, 0, True, 0.5, [], [])\n",
    "time.sleep(10)\n",
    "move = mr.stopAndGetRecording()\n",
    "# print move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = []\n",
    "for y in range (0,len(move[0][1])):\n",
    "    replay.append([move[x][1][y] for x in range(0,5)]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(replay)):\n",
    "    m.setAngles(pk.left_arm_tags, replay[x], 0.08)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관절 lock 해제\n",
    "m.setStiffnesses(\"LArm\",1.0)\n",
    "stiffnesses = m.getStiffnesses(\"LArm\")\n",
    "print stiffnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "\n",
    "\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "memory = n.ALProxy(\"ALMemory\", nao_ip, port)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if memory.getData(\"FrontTactilTouched\") :\n",
    "        print(time.ctime())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.521554, 0.467864, 0.648874, 0.547631, 0.547631, 0.00872665])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.20878, 1.19804, 1.22718, 1.24252, 1.24252, 1.25633])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.543937, 0.532513, 0.532513, 0.532513, 0.532513, 0.529877])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.33303, 1.05384, 0.420311, 0.541495, 0.541495, 1.31002])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([-0.693359, -1.20724, -0.81301, -0.211689, -0.211689, -0.0981748])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.302156, 0.628898, 0.361982, 0.277612, 0.277612, -0.242414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "time.sleep(3)\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    cv2.imwrite('images/save_encoding_%d.jpg' %(y), color_image)\n",
    "\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "time.sleep(3)\n",
    "frames = pipeline.wait_for_frames()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "color_frame = frames.get_color_frame()\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "cv2.imwrite('images/save_encodiwng_1.jpg', color_image)\n",
    "pipeline.stop()\n",
    "# Stack both images horizontally\n",
    "# images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "\n",
    "# Show images\n",
    "#cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "#cv2.imshow('RealSense', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- encoding: UTF-8 -*-\n",
    "\n",
    "\"\"\"Example: Get an image. Display it and save it using PIL.\"\"\"\n",
    "\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "# Get the service ALVideoDevice.\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 1 ,resolution, colorSpace, 5)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get a camera image.\n",
    "# image[6] contains the image data passed as an array of ASCII chars.\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Time the image transfer.\n",
    "print \"acquisition delay \", t1 - t0\n",
    "\n",
    "V.unsubscribe(videoClient)\n",
    "\n",
    "\n",
    "# Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "# package.\n",
    "\n",
    "# Get the image size and pixel array.\n",
    "imageWidth = naoImage[0]\n",
    "imageHeight = naoImage[1]\n",
    "naoImage[7] = 1\n",
    "array = naoImage[6]\n",
    "\n",
    "\n",
    "image_byte = str(bytearray(array))\n",
    "\n",
    "# Create a PIL Image from our pixel array.\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "\n",
    "# Save the image.\n",
    "im.save(\"camImage.png\", \"PNG\")\n",
    "\n",
    "im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replay motion capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.ab\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.521554, 0.467864, 0.648874, 0.547631, 0.547631, 0.00872665])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.20878, 1.19804, 1.22718, 1.24252, 1.24252, 1.25633])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.543937, 0.532513, 0.532513, 0.532513, 0.532513, 0.529877])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([1.33303, 1.05384, 0.420311, 0.541495, 0.541495, 1.31002])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([-0.693359, -1.20724, -0.81301, -0.211689, -0.211689, -0.0981748])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.4, 8.6])\n",
    "keys.append([0.302156, 0.628898, 0.361982, 0.277612, 0.277612, -0.242414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.510816, 0.814544, 0.849825, 0.849825, 0.297592, 0.297592])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([1.22565, 1.23179, 0.381961, 0.381961, 0.383495, 0.383495])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.557118, 0.536028, 0.536028, 0.536028, 0.525483, 0.525483])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([1.50177, 1.0247, 0.277651, 0.355884, 1.36831, 1.36831])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([-0.610524, -1.17963, -0.421845, -0.101243, -0.176408, -0.176408])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.26534, 0.874338, 1.30539, 1.00166, 0.788434, 0.788434])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 1 ,resolution, colorSpace, 5)\n",
    "\n",
    "imageWidth = 640\n",
    "imageHeight = 480\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);color_frame\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n",
    "    naoImage = V.getImageRemote(videoClient)\n",
    "    array = naoImage[6]\n",
    "    image_byte = str(bytearray(array))\n",
    "    im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "    im.save(\"images/motion_catpure%i.png\" %y, \"PNG\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "# len(keys)\n",
    "for y in range (0,len(keys)-2):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolationWithSpeed(names, joint_v[0], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 3    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client1\", 1 ,resolution, colorSpace, 10)\n",
    "\n",
    "imageWidth = 1280\n",
    "imageHeight = 960\n",
    "\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "array = naoImage[6]\n",
    "image_byte = str(bytearray(array))\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "im.save(\"images/motion_catpure_1280.png\", \"PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naoImage = V.getImageRemote(videoClient)\n",
    "type(naoImage[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "import sys\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "# Get the service ALVideoRecorder.\n",
    "VR = n.ALProxy(\"ALVideoRecorder\", nao_ip, port)\n",
    "\n",
    "# This records a 320*240 MJPG video at 10 fps.\n",
    "# Note MJPG can't be recorded with a framerate lower than 3 fps.\n",
    "VR.setResolution(2)\n",
    "VR.setFrameRate(10)\n",
    "VR.setVideoFormat(\"MJPG\")\n",
    "VR.setCameraID(1)\n",
    "\n",
    "VR.startRecording(\"/home/beom/\", \"video\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Video file is saved on the robot in the\n",
    "# /home/nao/recordings/cameras/ folder.\n",
    "videoInfo = VR.stopRecording()\n",
    "\n",
    "print \"Video was saved on the robot: \", videoInfo[1]\n",
    "print \"Num frames: \", videoInfo[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoInfo = VR.stopRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition delay  1.46774196625\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- encoding: UTF-8 -*-\n",
    "\n",
    "\"\"\"Example: Get an image. Display it and save it using PIL.\"\"\"\n",
    "\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "# Get the service ALVideoDevice.\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 0 ,resolution, colorSpace, 30)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get a camera image.\n",
    "# image[6] contains the image data passed as an array of ASCII chars.\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Time the image transfer.\n",
    "print \"acquisition delay \", t1 - t0\n",
    "\n",
    "V.unsubscribe(videoClient)\n",
    "\n",
    "\n",
    "# Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "# package.\n",
    "\n",
    "# Get the image size and pixel array.\n",
    "imageWidth = naoImage[0]\n",
    "imageHeight = naoImage[1]\n",
    "naoImage[7] = 1\n",
    "array = naoImage[6]\n",
    "\n",
    "\n",
    "image_byte = str(bytearray(array))\n",
    "# Create a PIL Image from our pixel array.\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "\n",
    "# Save the image.\n",
    "im.save(\"camImage1.png\", \"PNG\")\n",
    "im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
