{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "import sys\n",
    "import pepper_kinematics as pk\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "p = n.ALProxy(\"ALRobotPosture\", nao_ip, port)\n",
    "mr = n.ALProxy(\"ALMotionRecorder\", nao_ip, port)\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "Ph = n.ALProxy(\"ALPhotoCapture\", nao_ip, port)\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.getMethodList()\n",
    "m.rest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Posture stand Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move to initial pose\n",
    "p.goToPosture(\"StandInit\",0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관절 lock 해제\n",
    "m.setStiffnesses(\"LArm\",0.1)\n",
    "stiffnesses = m.getStiffnesses(\"LArm\")\n",
    "\n",
    "print stiffnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import time\n",
    "import numpy as np\n",
    "import naoqi as n\n",
    "\n",
    "\n",
    "T = n.ALProxy(\"ALTouch\", nao_ip, port)\n",
    "memory = n.ALProxy(\"ALMemory\", nao_ip, port)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if memory.getData(\"FrontTactilTouched\") :\n",
    "        print(time.ctime())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replay motion capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choregraphe simplified export in Python.\n",
    "from naoqi import ALProxy\n",
    "names = list()\n",
    "times = list()\n",
    "keys = list()\n",
    "\n",
    "names.append(\"RElbowRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.510816, 0.814544, 0.849825, 0.849825, 0.297592, 0.297592])\n",
    "\n",
    "names.append(\"RElbowYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([1.22565, 1.23179, 0.381961, 0.381961, 0.383495, 0.383495])\n",
    "\n",
    "names.append(\"RHand\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.557118, 0.536028, 0.536028, 0.536028, 0.525483, 0.525483])\n",
    "\n",
    "names.append(\"RShoulderPitch\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([1.50177, 1.0247, 0.277651, 0.355884, 1.36831, 1.36831])\n",
    "\n",
    "names.append(\"RShoulderRoll\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([-0.610524, -1.17963, -0.421845, -0.101243, -0.176408, -0.176408])\n",
    "\n",
    "names.append(\"RWristYaw\")\n",
    "times.append([2.4, 3.6, 4.8, 6, 7.2, 8.4])\n",
    "keys.append([0.26534, 0.874338, 1.30539, 1.00166, 0.788434, 0.788434])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 1 ,resolution, colorSpace, 5)\n",
    "\n",
    "imageWidth = 640\n",
    "imageHeight = 480\n",
    "\n",
    "for y in range (0,len(keys)):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolation(names, joint_v[0], times[0], True)\n",
    "    #naoImage = V.getImageRemote(videoClient)\n",
    "    #array = naoImage[6]\n",
    "    #image_byte = str(bytearray(array))\n",
    "    #im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "    #im.save(\"images/motion_catpure%i.png\" %y, \"PNG\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "m = n.ALProxy(\"ALMotion\", nao_ip, port)\n",
    "\n",
    "# len(keys)\n",
    "for y in range (0,len(keys)-2):\n",
    "    joint_v = []\n",
    "    joint_v.append([keys[x][y] for x in range (0,len(names))]);\n",
    "    m.angleInterpolationWithSpeed(names, joint_v[0], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naoqi as n\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "nao_ip = \"192.168.0.48\"\n",
    "\n",
    "port = 9559\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client1\", 1 ,resolution, colorSpace, 10)\n",
    "\n",
    "imageWidth = 640\n",
    "imageHeight = 320\n",
    "\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "array = naoImage[6]\n",
    "image_byte = str(bytearray(array))\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "im.save(\"images/motion_catpure_1280.png\", \"PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- encoding: UTF-8 -*-\n",
    "\n",
    "\"\"\"Example: Get an image. Display it and save it using PIL.\"\"\"\n",
    "\n",
    "import qi\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import Image\n",
    "\n",
    "\n",
    "# Get the service ALVideoDevice.\n",
    "\n",
    "V = n.ALProxy(\"ALVideoDevice\", nao_ip, port)\n",
    "resolution = 2    # VGA\n",
    "colorSpace = 11   # RGB\n",
    "\n",
    "videoClient = V.subscribeCamera(\"python_client\", 0 ,resolution, colorSpace, 30)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get a camera image.\n",
    "# image[6] contains the image data passed as an array of ASCII chars.\n",
    "naoImage = V.getImageRemote(videoClient)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Time the image transfer.\n",
    "print \"acquisition delay \", t1 - t0\n",
    "\n",
    "V.unsubscribe(videoClient)\n",
    "\n",
    "\n",
    "# Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "# package.\n",
    "\n",
    "# Get the image size and pixel array.\n",
    "imageWidth = naoImage[0]\n",
    "imageHeight = naoImage[1]\n",
    "naoImage[7] = 1\n",
    "array = naoImage[6]\n",
    "\n",
    "\n",
    "image_byte = str(bytearray(array))\n",
    "# Create a PIL Image from our pixel array.\n",
    "im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), image_byte)\n",
    "\n",
    "# Save the image.\n",
    "im.save(\"camImage1.png\", \"PNG\")\n",
    "im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"OpenCV feature detectors with ros CompressedImage Topics in python.\n",
    "\n",
    "This example subscribes to a ros topic containing sensor_msgs \n",
    "CompressedImage. It converts the CompressedImage into a numpy.ndarray, \n",
    "then detects and marks features in that image. It finally displays \n",
    "and publishes the new image - again as CompressedImage topic.\n",
    "\"\"\"\n",
    "__author__ =  'Simon Haller <simon.haller at uibk.ac.at>'\n",
    "__version__=  '0.1'\n",
    "__license__ = 'BSD'\n",
    "# Python libs\n",
    "import sys, time\n",
    "\n",
    "# numpy and scipy\n",
    "import numpy as np\n",
    "from scipy.ndimage import filters\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Ros libraries\n",
    "import roslib\n",
    "import rospy\n",
    "\n",
    "# Ros Messages\n",
    "from sensor_msgs.msg import CompressedImage\n",
    "# We do not use cv_bridge it does not support CompressedImage in python\n",
    "# from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "VERBOSE=False\n",
    "\n",
    "class image_feature:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''Initialize ros publisher, ros subscriber'''\n",
    "        # topic where we publish\n",
    "        self.image_pub = rospy.Publisher(\"/output/image_raw/compressed\",\n",
    "            CompressedImage)\n",
    "        # self.bridge = CvBridge()\n",
    "\n",
    "        # subscribed Topic\n",
    "        self.subscriber = rospy.Subscriber(\"/camera/image/compressed\",\n",
    "            CompressedImage, self.callback,  queue_size = 1)\n",
    "        if VERBOSE :\n",
    "            print \"subscribed to /camera/image/compressed\"\n",
    "\n",
    "\n",
    "    def callback(self, ros_data):\n",
    "        '''Callback function of subscribed topic. \n",
    "        Here images get converted and features detected'''\n",
    "        if VERBOSE :\n",
    "            print 'received image of type: \"%s\"' % ros_data.format\n",
    "\n",
    "        #### direct conversion to CV2 ####\n",
    "        np_arr = np.fromstring(ros_data.data, np.uint8)\n",
    "        image_np = cv2.imdecode(np_arr, cv2.CV_LOAD_IMAGE_COLOR)\n",
    "        #image_np = cv2.imdecode(np_arr, cv2.IMREAD_COLOR) # OpenCV >= 3.0:\n",
    "        \n",
    "        #### Feature detectors using CV2 #### \n",
    "        # \"\",\"Grid\",\"Pyramid\" + \n",
    "        # \"FAST\",\"GFTT\",\"HARRIS\",\"MSER\",\"ORB\",\"SIFT\",\"STAR\",\"SURF\"\n",
    "        method = \"GridFAST\"\n",
    "        feat_det = cv2.FeatureDetector_create(method)\n",
    "        time1 = time.time()\n",
    "\n",
    "        # convert np image to grayscale\n",
    "        featPoints = feat_det.detect(\n",
    "            cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY))\n",
    "        time2 = time.time()\n",
    "        if VERBOSE :\n",
    "            print '%s detector found: %s points in: %s sec.'%(method,\n",
    "                len(featPoints),time2-time1)\n",
    "\n",
    "        for featpoint in featPoints:\n",
    "            x,y = featpoint.pt\n",
    "            cv2.circle(image_np,(int(x),int(y)), 3, (0,0,255), -1)\n",
    "        \n",
    "        cv2.imshow('cv_img', image_np)\n",
    "        cv2.waitKey(2)\n",
    "\n",
    "        #### Create CompressedIamge ####\n",
    "        msg = CompressedImage()\n",
    "        msg.header.stamp = rospy.Time.now()\n",
    "        msg.format = \"jpeg\"\n",
    "        msg.data = np.array(cv2.imencode('.jpg', image_np)[1]).tostring()\n",
    "        # Publish new image\n",
    "        self.image_pub.publish(msg)\n",
    "        \n",
    "        #self.subscriber.unregister()\n",
    "\n",
    "def main(args):\n",
    "    '''Initializes and cleanup ros node'''\n",
    "    ic = image_feature()\n",
    "    rospy.init_node('image_feature', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print \"Shutting down ROS Image feature detector module\"\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import message_filters\n",
    "import cv2\n",
    "import rospy\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "def callback(rgb_msg, camera_info):\n",
    "   rgb_image = CvBridge().imgmsg_to_cv2(rgb_msg, desired_encoding=\"rgb8\")\n",
    "   camera_info_K = np.array(camera_info.K).reshape([3, 3])\n",
    "   camera_info_D = np.array(camera_info.D)\n",
    "   rgb_undist = cv2.undistort(rgb_image, camera_info_K, camera_info_D)\n",
    "\n",
    "rospy.init_node('my_node', anonymous=True)\n",
    "image_sub = message_filters.Subscriber('/ardrone/front/image_raw', Image)\n",
    "info_sub = message_filters.Subscriber('/ardrone/front/camera_info', CameraInfo)\n",
    "ts = message_filters.ApproximateTimeSynchronizer([image_sub, info_sub], 10, 0.2)\n",
    "ts.registerCallback(callback)\n",
    "rospy.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge\n",
    "bridge = CvBridge()\n",
    "cv_image = bridge.imgmsg_to_cv2(image_message, desired_encoding='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import std_msgs.msg\n",
    "image_msg = std_msgs.msg.Image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roslib\n",
    "import sys\n",
    "import rospy\n",
    "import cv2\n",
    "from std_msgs.msg import String\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "bridge = CvBridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_image = bridge.imgmsg_to_cv2(\"/pepper_robot/camera/front/image_raw\", desired_encoding='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rows,cols,channels) = cv_image.shape\n",
    "if cols > 60 and rows > 60 :\n",
    "  cv2.circle(cv_image, (50,50), 10, 255)\n",
    "\n",
    "cv2.imshow(\"Image window\", cv_image)\n",
    "cv2.waitKey(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ehlflfrk djqtsmsep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roslib\n",
    "import sys\n",
    "import rospy\n",
    "import cv2\n",
    "from std_msgs.msg import String\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roslib\n",
    "import sys\n",
    "import rospy\n",
    "import cv2\n",
    "from std_msgs.msg import String\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "class image_converter:\n",
    "\n",
    "  def __init__(self):\n",
    "    self.image_pub = rospy.Publisher(\"image_topic_2\",Image,queue_size = 10)\n",
    "\n",
    "    self.bridge = CvBridge()\n",
    "    self.image_sub = rospy.Subscriber(\"/camera/image_raw\",Image,self.callback)\n",
    "\n",
    "  def callback(self,data):\n",
    "    try:\n",
    "      cv_image = self.bridge.imgmsg_to_cv2(data, \"bgr8\")\n",
    "    except CvBridgeError as e:\n",
    "      print(e)\n",
    "\n",
    "    (rows,cols,channels) = cv_image.shape\n",
    "    if cols > 60 and rows > 60 :\n",
    "      cv2.circle(cv_image, (50,50), 10, 255)\n",
    "\n",
    "    cv2.imshow(\"Image window\", cv_image)\n",
    "    cv2.waitKey(3)\n",
    "\n",
    "    try:\n",
    "      self.image_pub.publish(self.bridge.cv2_to_imgmsg(cv_image, \"bgr8\"))\n",
    "    except CvBridgeError as e:\n",
    "      print(e)\n",
    "\n",
    "def main(args):\n",
    "  ic = image_converter()\n",
    "  rospy.init_node('image_converter', anonymous=True)\n",
    "  try:\n",
    "    rospy.spin()\n",
    "  except KeyboardInterrupt:\n",
    "    print(\"Shutting down\")\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
